{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Vader Sentment\n",
    "Media Sentiment Analysis\n",
    "Analyses the Sentiment on the last 100 tweets of the Media Channels:\n",
    "BBC,CNN,CBS,FoxNew and New York Times\n",
    "Also plots the overall Sentiment analysis on each of the channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import tweepy\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Import and Initialize Sentiment Analyzer\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Twitter API Keys\n",
    "consumer_key = \"Provide your key\"\n",
    "consumer_secret = \"Provide your key\"\n",
    "access_token = \"Provide your key\"\n",
    "access_token_secret = \"Provide your key\"\n",
    "\n",
    "# Setup Tweepy API Authentication\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, parser=tweepy.parsers.JSONParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Target Search Term of the various Media channels\n",
    "Media_users = (\"@BBC\", \"@CBS\", \"@CNN\",\"@FoxNews\", \"@nytimes\")\n",
    "\n",
    "# Array to hold sentiment\n",
    "Sentiment_array = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extracting the first 100 tweets in each Media Channel\n",
    "print(\"Beginning of extraction of the posted tweets from the media channels\")\n",
    "\n",
    "for user in Media_users:\n",
    "    # Setting the tweet count as 100\n",
    "    tweetcount=100\n",
    "    print(\"Extracting tweets from %s\"%user)\n",
    "    \n",
    "    # Extracting 5 pages of tweets\n",
    "    for x in range(5):\n",
    "        public_tweets=api.user_timeline(user,page=x)\n",
    "        # For each tweet \n",
    "        for tweet in public_tweets:\n",
    "            #Calculating the compound,positive,negative and neutral value for each tweet\n",
    "            compound = analyzer.polarity_scores(tweet[\"text\"])[\"compound\"]\n",
    "            pos = analyzer.polarity_scores(tweet[\"text\"])[\"pos\"]\n",
    "            neu = analyzer.polarity_scores(tweet[\"text\"])[\"neu\"]\n",
    "            neg = analyzer.polarity_scores(tweet[\"text\"])[\"neg\"]\n",
    "            # Store Tweet in Array\n",
    "            Sentiment_array.append({\"Media\":user,\n",
    "                                    \"Tweet Text\":tweet[\"text\"],\n",
    "                                    \"Compound\":compound,\n",
    "                                    \"Positive\":pos,\n",
    "                                    \"Negative\":neg,\n",
    "                                    \"Neutral\":neu,\n",
    "                                    \"Date\":tweet[\"created_at\"],\n",
    "                                    \"Tweets Ago\":tweetcount})\n",
    "            #Decreasing tweet count by 1\n",
    "            tweetcount-=1\n",
    "\n",
    "print(\"End of Extraction of Tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating a dataframe from the Sentiment Array\n",
    "Sentiment_DF=pd.DataFrame.from_dict(Sentiment_array)\n",
    "# Removing the '@' from Media column in the data frame\n",
    "Sentiment_DF['Media'] = Sentiment_DF['Media'].map(lambda x: x.lstrip('@'))\n",
    "\n",
    "# Re_arranging the order of columns before saving into CSV file\n",
    "Sentiment_DF=Sentiment_DF[[\"Media\",\"Date\",\"Tweet Text\",\"Compound\",\"Positive\",\"Negative\",\"Neutral\",\"Tweets Ago\"]]\n",
    "# Storing into a CSV File\\\n",
    "Sentiment_DF.to_csv(\"Output/Media_SentimentAnalysis.csv\")\n",
    "\n",
    "Sentiment_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating an array with the unique Media sources in the data frame\n",
    "Media_Source=Sentiment_DF[\"Media\"].unique()\n",
    "\n",
    "#Plotting the graph for each media source\n",
    "for media in Media_Source:\n",
    "    # Creating a temporary data frame to store for only one media channel at a time\n",
    "    Temp_DF=Sentiment_DF[Sentiment_DF[\"Media\"]==media]\n",
    "    plt.scatter(Temp_DF[\"Tweets Ago\"],Temp_DF[\"Compound\"], marker=\"o\", linewidth=0, alpha=0.8, label=media,\n",
    "                facecolors=Temp_DF.Media.map({\"BBC\": \"orange\", \"CBS\" : \"green\",  \"CNN\": 'red',\n",
    "                                              \"FoxNews\":\"blue\",\"nytimes\":\"yellow\"}))\n",
    "\n",
    "\n",
    "#plt.hlines(0,0,np.arange(len(Sentiment_DF[\"Compound\"])),alpha=1)\n",
    "# Setting the legend \n",
    "plt.legend(bbox_to_anchor = (1,1),title=\"Media Sources\")\n",
    "# Setting the title,x_axis and y_axis labels\n",
    "plt.title(\"Sentiment Analysis of Media Tweets (%s)\" % (time.strftime(\"%x\")), fontsize=14)\n",
    "plt.xlabel(\"Tweets Ago\")\n",
    "plt.ylabel(\"Tweet Polarity\")\n",
    "#Setting the x_axis and y_axis limits\n",
    "plt.xlim(101,0)\n",
    "plt.ylim(-1,1)\n",
    "# Setting the grid\n",
    "plt.grid(True)\n",
    "\n",
    "# Saving the figue\n",
    "plt.savefig(\"Output/Sentiment Analysis of Media Tweets.png\",bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculating the mean for each Media channel and storing to a dataframe\n",
    "Media_Compound_Means=Sentiment_DF.groupby(\"Media\").mean()[\"Compound\"].to_frame()\n",
    "#Resetting the index \n",
    "Media_Compound_Means.reset_index(inplace=True)\n",
    "\n",
    "Media_Compound_Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setting the x_axis and y-axis value\n",
    "x_axis=Media_Compound_Means.index.values\n",
    "y_axis=Media_Compound_Means[\"Compound\"]\n",
    "\n",
    "# Intializing the plots\n",
    "fig,ax=plt.subplots()\n",
    "\n",
    "#Setting the plot and assigning the color based on the Positive or not value\n",
    "bars=ax.bar(x_axis,y_axis,align=\"edge\",width=1,linewidth=1,\n",
    "            edgecolor='black',color=[\"orange\",\"green\",\"red\",\"blue\",\"yellow\"])\n",
    "\n",
    "# Setting the ticks for the bar graph\n",
    "tick_locations = [value+0.5 for value in range(len(x_axis))]\n",
    "plt.xticks(tick_locations,[\"BBC\",\"CBS\",\"CNN\",\"Fox\",\"NYT\"])\n",
    "\n",
    "# Setting the text label in the bar graph\n",
    "# If value is positive then put True in the Summary else place False, for changing the color based on the value\n",
    "Media_Compound_Means[\"Positive\"]=Media_Compound_Means[\"Compound\"]>0\n",
    "# Assign the height based on whether it is a  positive value\n",
    "height = Media_Compound_Means.Positive.map({True: 0.03 , False: -0.03})\n",
    "# Setting the value label on the each bar\n",
    "for bar in bars:\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height()+height[bars.index(bar)],\n",
    "            round(Media_Compound_Means[\"Compound\"][bars.index(bar)],3),ha='center', va='bottom')\n",
    "\n",
    "\n",
    "# Setting the x_axis limits\n",
    "ax.set_xlim(0, len(x_axis))\n",
    "#Setting the y_axis limits dynamically by finding the maximum and minimum value in y-axis\n",
    "ax.set_ylim(min(y_axis)-0.1, max(y_axis)+0.1)\n",
    "\n",
    "# Setting a horizontal line at y=0\n",
    "plt.hlines(0,0,len(x_axis))\n",
    "\n",
    "# Setting the title of the graph\n",
    "ax.set_title(\"Overall Media Sentiment based on Twitter (%s)\" % (time.strftime(\"%x\")), fontsize=14)\n",
    "# Setting the y_axis label\n",
    "ax.set_ylabel(\"Twitter Polarity\")\n",
    "\n",
    "# Saving the graph\n",
    "plt.savefig(\"Output/Overall_Media_Sentiment_based_on_Twitter.png\",bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Summary\n",
    "Based on the analysis performed on 5 December 2018\n",
    "CBS has the most positive sentiment analysis compared to the rest followed by BBC. \n",
    "BBC has the most neutralsentiment analysis compared to the rest.\n",
    "CNN has the most negative sentiment analysis compared to remaining followed by Fox and New York Times respectively."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
