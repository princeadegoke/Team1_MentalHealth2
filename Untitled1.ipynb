{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "InaPyBot\n",
    "The bot receives tweets via mentions and in turn performs sentiment analysis on the most recent twitter account specified in the mention\n",
    "For example, when a user tweets, \"#InaPyBot @CNN\" it will trigger a sentiment analysis on the CNN twitter feed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import tweepy\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "#To get the current date\n",
    "import datetime\n",
    "\n",
    "\n",
    "# Import and Initialize Sentiment Analyzer\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Twitter API Keys\n",
    "consumer_key = \"Your key here\"\n",
    "consumer_secret = \"Your key here\"\n",
    "access_token = \"Your key here\"\n",
    "access_token_secret = \"Your key here\"\n",
    "\n",
    "# Setup Tweepy API Authentication\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, parser=tweepy.parsers.JSONParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_sentiment(sentiment_df,user):\n",
    "    sentiment_df.plot(\"Tweets Ago\",\"Compound\",marker=\"o\", linewidth=0.8, alpha=0.8,linestyle=\"-\",label=user)\n",
    "    plt.legend(bbox_to_anchor = (1,1),title=\"Tweets\")\n",
    "    \n",
    "    plt.xlabel(\"Tweets Ago\")\n",
    "    plt.ylabel(\"Tweet Polarity\")\n",
    "    plt.title(\"Sentiment Analysis of %s (%s)\"%(user.replace(\"@\",\"\"),datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')))\n",
    "    \n",
    "    plt.xlim(502,-2)\n",
    "    plt.grid(True)\n",
    "    filename = \"PyBotOutput/Sentiment_Analysis_of_\"+user.replace(\"@\",\"\")+\".png\"\n",
    "    plt.savefig(filename,bbox_inches='tight')\n",
    "    plt.show()\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Retrieve_Tweets(user):\n",
    "    # Array to hold sentiment\n",
    "    Sentiment_array = []\n",
    "    # Setting the tweet count as 500\n",
    "    tweetcount=500\n",
    "    print(\"Extracting tweets from %s\"%user)\n",
    "\n",
    "    # Extracting  pages of tweets\n",
    "    for x in range(25):\n",
    "        public_tweets=api.user_timeline(user,page=x)\n",
    "        # For each tweet \n",
    "        for tweet in public_tweets:\n",
    "            #Calculating the compound,positive,negative and neutral value for each tweet\n",
    "            compound = analyzer.polarity_scores(tweet[\"text\"])[\"compound\"]\n",
    "            pos = analyzer.polarity_scores(tweet[\"text\"])[\"pos\"]\n",
    "            neu = analyzer.polarity_scores(tweet[\"text\"])[\"neu\"]\n",
    "            neg = analyzer.polarity_scores(tweet[\"text\"])[\"neg\"]\n",
    "            # Store Tweet in Array\n",
    "            Sentiment_array.append({\"Media\":user,\n",
    "                                    \"Tweet Text\":tweet[\"text\"],\n",
    "                                    \"Compound\":compound,\n",
    "                                    \"Positive\":pos,\n",
    "                                    \"Negative\":neg,\n",
    "                                    \"Neutral\":neu,\n",
    "                                    \"Date\":tweet[\"created_at\"],\n",
    "                                    \"Tweets Ago\":tweetcount})\n",
    "            #Decreasing tweet count by 1\n",
    "            tweetcount-=1\n",
    "\n",
    "    print(\"End of Extraction of Tweets\")\n",
    "\n",
    "    # Creating a dataframe from the Sentiment Array\n",
    "    Sentiment_DF=pd.DataFrame.from_dict(Sentiment_array)\n",
    "    # Removing the '@' from Media column in the data frame\n",
    "    Sentiment_DF['Media'] = Sentiment_DF['Media'].map(lambda x: x.lstrip('@'))\n",
    "\n",
    "    # Re_arranging the order of columns before saving into CSV file\n",
    "    Sentiment_DF=Sentiment_DF[[\"Media\",\"Date\",\"Tweet Text\",\"Compound\",\"Positive\",\"Negative\",\"Neutral\",\"Tweets Ago\"]]\n",
    "    filename=plot_sentiment(Sentiment_DF,user)\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Search_Request():\n",
    "    # An array to store the neccessary information on each tweet\n",
    "    Query_array=[]\n",
    "    \n",
    "    # If the file Request.csv exists \n",
    "    try:\n",
    "        # Read the csv file\n",
    "        Query_DF=pd.read_csv(\"PyBotOutput/Requests.csv\")\n",
    "        # Get the last id from the first row of the csv file\n",
    "        lastid=Query_DF[\"Tweet ID\"][Query_DF.index[0]]\n",
    "        # Get the request using api.search\n",
    "        request=api.search(\"#InaPyBot\",since_id=lastid)\n",
    "        \n",
    "        \n",
    "        # For each new tweet \n",
    "        for tweet in request[\"statuses\"]:\n",
    "            \n",
    "            # Check if there is requests for user mention from the tweet\n",
    "            if not(not tweet[\"entities\"][\"user_mentions\"]):\n",
    "                \n",
    "                # Check if there is any previous request for that user mention with the content of csv file\n",
    "                if Query_DF[\"User Request\"].all()!=tweet[\"entities\"][\"user_mentions\"][0][\"screen_name\"]:\n",
    "                    # Appending the necessary details to the array\n",
    "                    Query_array.append({\"User Name\":tweet[\"user\"][\"screen_name\"],\n",
    "                                \"User Request\":tweet[\"entities\"][\"user_mentions\"][0][\"screen_name\"],\n",
    "                                \"Tweet ID\":tweet[\"id\"],\n",
    "                                \"Created On\":tweet[\"created_at\"]\n",
    "                                })\n",
    "                    # Retrieve and plot the graph for the requested user mention\n",
    "                    filename=Retrieve_Tweets(tweet[\"entities\"][\"user_mentions\"][0][\"screen_name\"])\n",
    "                    reply_text=\"New Tweet Analysis: @%s (Thanks @%s)\"%(\n",
    "                            tweet[\"entities\"][\"user_mentions\"][0][\"screen_name\"]\n",
    "                           ,tweet[\"user\"][\"screen_name\"])\n",
    "                    # Reply to tweet with the image file\n",
    "                    api.update_with_media(filename=filename,status=reply_text,in_reply_to_status_id=tweet[\"id\"])\n",
    "                    \n",
    "                    # Convert the array into a dataframe\n",
    "                    New_DF=pd.DataFrame.from_dict(Query_array)\n",
    "                    # Append the new temporary array into the main dataframe\n",
    "                    Query_DF=New_DF.append(Query_DF)\n",
    "                    \n",
    "                # If a previous request for that user mention has already been processed\n",
    "                else:\n",
    "                    print(\"The request for %s has already been processed\"%tweet[\"entities\"][\"user_mentions\"][0][\"screen_name\"])\n",
    "                    # Try and error in case that status has already been processed and to avoid duplication error\n",
    "                    try:\n",
    "                        reply_text = \"Thank you for your tweet @%s! Sorry, %s request has already been tweeted!\"%(\n",
    "                                tweet[\"user\"][\"screen_name\"],\n",
    "                                tweet[\"entities\"][\"user_mentions\"][0][\"screen_name\"])\n",
    "                        # Reply to tweet with the Sorry Message\n",
    "                        api.update_status(reply_text,in_reply_to_status_id=tweet[\"id\"])\n",
    "                    except:\n",
    "                        pass\n",
    "    \n",
    "            # If there is no request from user mentions then the Tweet request format is incorrect\n",
    "            else:\n",
    "                reply_text=\"@%s \\nTweet text:%s \\nError: Not in the specified format or doesnot have an existing user in Twitter\"%(\n",
    "                    tweet[\"user\"][\"screen_name\"],tweet[\"text\"])\n",
    "                # Reply to tweet saying the format is incorrect\n",
    "                api.update_status(reply_text,in_reply_to_status_id=tweet[\"id\"])\n",
    "                print(reply_text)\n",
    "                \n",
    "        \n",
    "    # If the Request.csv file doesnot exist, this is mainly for the first time when the code is deployed\n",
    "    except FileNotFoundError:\n",
    "        \n",
    "        # Placing the first tweet id of one from my timeline\n",
    "        lastid=948692161024978945\n",
    "        # Searching for tweets using the handle and since the last id\n",
    "        request=api.search(\"#InaPyBot\",since_id=lastid)\n",
    "        \n",
    "        # For each tweet in the response\n",
    "        for tweet in request[\"statuses\"]:\n",
    "            \n",
    "            # Check if there is requests for user mention from the tweet\n",
    "            if not(not tweet[\"entities\"][\"user_mentions\"]):\n",
    "                # Appending the necessary details to the array\n",
    "                Query_array.append({\"User Name\":tweet[\"user\"][\"screen_name\"],\n",
    "                                \"User Request\":tweet[\"entities\"][\"user_mentions\"][0][\"screen_name\"],\n",
    "                                \"Tweet ID\":tweet[\"id\"],\n",
    "                                \"Created On\":tweet[\"created_at\"]\n",
    "                                })\n",
    "                # Retrieve and plot the graph for the requested user mention\n",
    "                filename=Retrieve_Tweets(tweet[\"entities\"][\"user_mentions\"][0][\"screen_name\"])\n",
    "                reply_text=\"New Tweet Analysis: @%s (Thanks @%s)\"%(\n",
    "                        tweet[\"entities\"][\"user_mentions\"][0][\"screen_name\"],\n",
    "                        tweet[\"user\"][\"screen_name\"])\n",
    "                \n",
    "                # Reply to tweet with the image file\n",
    "                api.update_with_media(filename=filename,status=reply_text,in_reply_to_status_id=tweet[\"id\"])\n",
    "                # Append the array into the main dataframe\n",
    "                Query_DF=pd.DataFrame.from_dict(Query_array)\n",
    "            \n",
    "            # If there is no request from user mentions then the Tweet request format is incorrect\n",
    "            else:\n",
    "                reply_text=\"@%s \\nTweet text:%s \\nError: Not in the specified format or doesnot have an existing user in Twitter\"%(\n",
    "                    tweet[\"user\"][\"screen_name\"],tweet[\"text\"])\n",
    "                # Reply to tweet saying the format is incorrect\n",
    "                api.update_status(reply_text,in_reply_to_status_id=tweet[\"id\"])\n",
    "                print(reply_text)\n",
    "\n",
    "                \n",
    "        #Query_DF=pd.DataFrame.from_dict(Query_array)\n",
    "    \n",
    "    Query_DF.to_csv(\"PyBotOutput/Requests.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    Search_Request()\n",
    "    time.sleep(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
